{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWCJlLAmkcSu"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_j7MoarkcS9",
        "outputId": "2adf574b-8260-4f14-b687-7a9c1839619b"
      },
      "source": [
        "tf.executing_eagerly() \n",
        "#https://medium.com/coding-blocks/eager-execution-in-tensorflow-a-more-pythonic-way-of-building-models-e461810618c8"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UQTQWytliSs"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wyhKgaCkcTA"
      },
      "source": [
        "  text = open(\"shakespeare.txt\",'r').read()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNopwevKkcTB"
      },
      "source": [
        "vocab = sorted(set(text)) # set is for distinct elements"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJTOuZERkcTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a4d9118-5263-41cc-b770-493b4b6e92b5"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '>',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '[',\n",
              " ']',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '|',\n",
              " '}']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oum4ZglgkcTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea65c1f-0a66-4d00-f60a-eb7238c36448"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6wkx1-bkcTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8be1a3-19bf-4142-bc82-84ea0fd37e59"
      },
      "source": [
        "for pair in enumerate(vocab):\n",
        "    print(pair)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '\\n')\n",
            "(1, ' ')\n",
            "(2, '!')\n",
            "(3, '\"')\n",
            "(4, '&')\n",
            "(5, \"'\")\n",
            "(6, '(')\n",
            "(7, ')')\n",
            "(8, ',')\n",
            "(9, '-')\n",
            "(10, '.')\n",
            "(11, '0')\n",
            "(12, '1')\n",
            "(13, '2')\n",
            "(14, '3')\n",
            "(15, '4')\n",
            "(16, '5')\n",
            "(17, '6')\n",
            "(18, '7')\n",
            "(19, '8')\n",
            "(20, '9')\n",
            "(21, ':')\n",
            "(22, ';')\n",
            "(23, '<')\n",
            "(24, '>')\n",
            "(25, '?')\n",
            "(26, 'A')\n",
            "(27, 'B')\n",
            "(28, 'C')\n",
            "(29, 'D')\n",
            "(30, 'E')\n",
            "(31, 'F')\n",
            "(32, 'G')\n",
            "(33, 'H')\n",
            "(34, 'I')\n",
            "(35, 'J')\n",
            "(36, 'K')\n",
            "(37, 'L')\n",
            "(38, 'M')\n",
            "(39, 'N')\n",
            "(40, 'O')\n",
            "(41, 'P')\n",
            "(42, 'Q')\n",
            "(43, 'R')\n",
            "(44, 'S')\n",
            "(45, 'T')\n",
            "(46, 'U')\n",
            "(47, 'V')\n",
            "(48, 'W')\n",
            "(49, 'X')\n",
            "(50, 'Y')\n",
            "(51, 'Z')\n",
            "(52, '[')\n",
            "(53, ']')\n",
            "(54, '_')\n",
            "(55, '`')\n",
            "(56, 'a')\n",
            "(57, 'b')\n",
            "(58, 'c')\n",
            "(59, 'd')\n",
            "(60, 'e')\n",
            "(61, 'f')\n",
            "(62, 'g')\n",
            "(63, 'h')\n",
            "(64, 'i')\n",
            "(65, 'j')\n",
            "(66, 'k')\n",
            "(67, 'l')\n",
            "(68, 'm')\n",
            "(69, 'n')\n",
            "(70, 'o')\n",
            "(71, 'p')\n",
            "(72, 'q')\n",
            "(73, 'r')\n",
            "(74, 's')\n",
            "(75, 't')\n",
            "(76, 'u')\n",
            "(77, 'v')\n",
            "(78, 'w')\n",
            "(79, 'x')\n",
            "(80, 'y')\n",
            "(81, 'z')\n",
            "(82, '|')\n",
            "(83, '}')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPltMnVjkcTF"
      },
      "source": [
        "# can't slice a list of tuples so convert them into dictionary"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjWLaReEkcTF"
      },
      "source": [
        "char_to_ind = {char:ind for ind,char in enumerate(vocab)}\n",
        "#char:ind- this is the way we want the ouput to be\n",
        "# ind,char in enumerate coz that's how the tuples in the vocabs are..integer and dn character"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_orHzJvkcTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e143a6bb-4e95-4141-fc00-d4b116c921bc"
      },
      "source": [
        "char_to_ind"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm3PDE63kcTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8f82a2-d985-4fbc-daf2-9472a149d792"
      },
      "source": [
        "char_to_ind['H']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IIBfXXnkcTI"
      },
      "source": [
        "ind_to_char = np.array(vocab)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GihVwsQUkcTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8040c93f-6bcd-47e4-e3ad-8926d2e09dcc"
      },
      "source": [
        "ind_to_char"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
              "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
              "       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLF617NJkcTJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd3de3bb-1101-433a-814f-646931b82d4d"
      },
      "source": [
        "ind_to_char[33]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'H'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xPO_TGakcTL"
      },
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text]) # the entire text "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sy0Qfy2kcTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56884e63-d6a2-48fe-92c1-22d8b3449cd3"
      },
      "source": [
        "encoded_text"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1, ..., 30, 39, 29])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGfN9D4FkcTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3fb572-ff8a-48dd-ee25-43d9a61c9149"
      },
      "source": [
        "encoded_text.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5445609,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmfofGCRkcTM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "95ba8fed-94c4-4f2a-b980-a64830c942fc"
      },
      "source": [
        "sample = text[:500]\n",
        "sample"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3nPyw08kcTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c8c9cb-b0d2-4b36-d889-e7ae32045bd0"
      },
      "source": [
        "encoded_text[:500]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
              "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
              "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
              "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
              "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
              "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
              "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
              "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
              "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
              "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
              "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
              "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
              "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
              "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
              "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
              "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
              "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
              "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
              "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
              "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
              "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
              "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
              "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
              "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
              "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
              "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
              "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
              "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
              "        1, 70, 78, 69,  1, 57, 76])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANzoILuRkcTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b685541-ea73-4e73-cc7a-7be6d0314fa4"
      },
      "source": [
        "print(text[:500])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dr0d6ookcTO"
      },
      "source": [
        "line = \"From fairest creatures we desire increase\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qya6dJigkcTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33aca355-8ee6-4da9-abc3-3c73ab02de59"
      },
      "source": [
        "len(line)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L82Fy3RkcTP"
      },
      "source": [
        "# our training sequence must be long enough in order to pick up the general structure of the text"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7HZJxaYkcTP"
      },
      "source": [
        "lines = '''\n",
        "From fairest creatures we desire increase,\n",
        "  That thereby beauty's rose might never die,\n",
        "  But as the riper should by time decease,\n",
        "'''\n",
        "#triple quotes coz  it is multi line"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f48ogyPkcTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6332a0-e22d-442b-ca18-428602ee21a5"
      },
      "source": [
        "len(lines)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcGNNC7MkcTQ"
      },
      "source": [
        "seq_len =120"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAMLhnBdkcTQ"
      },
      "source": [
        "total_num_seq = len(text)//(seq_len+1) # coz of zero indexing\n",
        "#// divides and drops reminder"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU5_FbpVkcTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ded0a8-3b21-4119-e987-469021e5443e"
      },
      "source": [
        "total_num_seq"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5mdccmDkcTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2073f61a-b0d7-453a-f97c-3cda5b241183"
      },
      "source": [
        "#https://www.geeksforgeeks.org/tensorflow-tf-data-dataset-from_tensor_slices/\n",
        "char_dataset =tf.data.Dataset.from_tensor_slices(encoded_text) \n",
        "#https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "char_dataset"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp9VX6E-kcTS"
      },
      "source": [
        "sequences = char_dataset.batch(seq_len+1,drop_remainder=True)\n",
        "#when we take input text/target text, we have to take([:-1])/([1:]) which should be equal to 120 i.e the length of sequences,\n",
        "#this can be achieved by taking seq_len + 1 in batches.\n",
        "#if we take only seq_len, dn input/target_text will have length of 119.\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c6ZJG4NkcTT"
      },
      "source": [
        "def create_seq_targets(seq):\n",
        "    input_txt = seq[:-1] #hello I am Prita\n",
        "    target_txt = seq[1:] #ello I am Pritam\n",
        "    \n",
        "    return input_txt,target_txt"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFwcTHogkcTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fac371-c518-4551-e8e5-798e41921228"
      },
      "source": [
        "dataset = sequences.map(create_seq_targets) #MAPS the function of create_seq_targets to sequences\n",
        "dataset.take(1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((120,), (120,)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGNj8OnjkcTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78760d23-54ae-4c08-f11a-54429d1da0dc"
      },
      "source": [
        "for input_txt,target_txt in dataset.take(1):# first sequence\n",
        "    print(input_txt.numpy())\n",
        "    print(\" \".join(ind_to_char[input_txt.numpy()]))  #joins all the characters and  adds space between the chars\n",
        "    print('\\n')\n",
        "    print(target_txt.numpy())\n",
        "    print(\"\".join(ind_to_char[target_txt.numpy()]))\n",
        "    # the last para has a extra white space\n",
        "    # here dataset.take(1) will always return the first sequence because the data is not shuffled "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                                           1 \n",
            "     F r o m   f a i r e s t   c r e a t u r e s   w e   d e s i r e   i n c r e a s e , \n",
            "     T h a t   t h e r e b y   b e a u t y ' s   r o s e   m i g h t   n e v e r   d i e , \n",
            "     B u t\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3fX6aCXzb5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c7e035-99b9-42ed-9d69-feb037a520f2"
      },
      "source": [
        "input_txt"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120,), dtype=int64, numpy=\n",
              "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
              "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
              "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
              "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
              "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
              "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
              "       75])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V674jrHkcTV"
      },
      "source": [
        "batch_size = 128\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeKRlcizkcTV"
      },
      "source": [
        "buffer_size = 10000 # we shuffle in batches coz if we shuffle the entire data set , we might end up commiting error\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)\n",
        "#It is very important that dataset is shuffled well to avoid any element of bias/patterns \n",
        "#take 10k of those elements and shuffle them"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Cej4srEkcTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba62049a-5345-4475-8834-8b4c3bf6775e"
      },
      "source": [
        "dataset\n",
        "#input sequence 128,120 ;-> 128 sequence with 120 characters long\n",
        "#target sequence 128,120"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slf5KlzkBKvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a3883b-186d-48a1-d6b7-785f56a2a3d7"
      },
      "source": [
        "dataset.take(1)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8rGIt6KkcTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96918862-3d12-487b-ce69-2fa28dc5f88a"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tITY8IDkcTX"
      },
      "source": [
        "embed_dim = 64 #should be around the same size as vocab, something we can play around with\n",
        "#this is for our embedding layer\n",
        "#embedding turns positive integers into dense vectors"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdKuIt2UkcTY"
      },
      "source": [
        "rnn_neurons = 1026"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoTSs8I7kcTY"
      },
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5khcY_zzkcTZ"
      },
      "source": [
        "#since we are one hot encoded, we need from_logits to be true, hence we define it"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npdMxq36kcTZ"
      },
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True,)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn1kpMtYkcTa"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,GRU,Dense"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX4qjyyxkcTa"
      },
      "source": [
        "#None means it is a dynamic shape. It can take any value depending on the batch size you choose.\n",
        "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size,embed_dim,batch_input_shape = [batch_size,None]))\n",
        "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.compile('adam',loss = sparse_cat_loss)\n",
        "\n",
        "\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39pfc-1OkcTb"
      },
      "source": [
        "model = create_model(vocab_size=vocab_size,embed_dim=embed_dim,rnn_neurons=rnn_neurons,batch_size=batch_size)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYlC7oBakcTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47e26ac-9791-4048-8346-0e2bb27d38a8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (128, None, 64)           5376      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (128, None, 1026)         3361176   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (128, None, 84)           86268     \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn-pRSwakcTc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacecd46-d0d0-487d-9239-35f1cc17097f"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(3):\r\n",
        "  print(input_example_batch)\r\n",
        "  \r\n",
        "  # from here till (model. fit) we are just checking  to ensure that everyting is fine\r\n",
        "  #dataset.take(3) will take 3 random samples from the dataset\r\n",
        "  #each time the cell is run, we will get different input_example_batch\r\n",
        "  #this is because our dataset now has been shuffled.#dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True) \r\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[60 10  0 ...  1  5 57]\n",
            " [75 70  1 ... 26 76 61]\n",
            " [ 1 57 60 ... 63 60 73]\n",
            " ...\n",
            " [ 8  1 63 ...  0  1  1]\n",
            " [59  1 73 ... 75 63 80]\n",
            " [60 67 67 ...  1 63 60]], shape=(128, 120), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[60  1 64 ... 71 67 60]\n",
            " [ 1  1  1 ... 56 77 60]\n",
            " [73 60 69 ... 10  0  1]\n",
            " ...\n",
            " [73 75  1 ... 70 61  1]\n",
            " [56 69 70 ... 63  8  1]\n",
            " [40 37 26 ... 60  1 74]], shape=(128, 120), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[68 60  1 ... 66 60  1]\n",
            " [75 56 64 ... 68 80  1]\n",
            " [60 66 74 ... 67 56 75]\n",
            " ...\n",
            " [56 69 64 ... 59 25  1]\n",
            " [64 68  1 ... 75  1 52]\n",
            " [ 0  1  1 ...  1 57 76]], shape=(128, 120), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5fe1DLy7hkm"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\r\n",
        "  example_batch_predictions = model(input_example_batch)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLBKntoR0YUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dada049-239d-4da7-dbe5-39126dd8dbb4"
      },
      "source": [
        " example_batch_predictions[0]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 84), dtype=float32, numpy=\n",
              "array([[ 0.0056132 , -0.00504818, -0.00134756, ..., -0.00218874,\n",
              "         0.00048715, -0.00061802],\n",
              "       [ 0.00366667, -0.00505131,  0.00339404, ...,  0.00018865,\n",
              "         0.00199569, -0.00685113],\n",
              "       [ 0.00445918, -0.00572371,  0.00384926, ..., -0.00289748,\n",
              "         0.00588458, -0.00534065],\n",
              "       ...,\n",
              "       [-0.00202772, -0.00207145, -0.00556949, ..., -0.00127369,\n",
              "        -0.00310731,  0.00567011],\n",
              "       [ 0.0047515 , -0.00695132, -0.00409351, ..., -0.00198909,\n",
              "        -0.00106151,  0.00205109],\n",
              "       [ 0.00323016, -0.00104503, -0.00051489, ...,  0.00716028,\n",
              "        -0.00155583, -0.00031859]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFVjisgCjYJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48aa283-57ca-43cd-d135-d9e72afbb948"
      },
      "source": [
        "  example_batch_predictions.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128, 120, 84])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKczi0km28z1"
      },
      "source": [
        "sample_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\r\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVDPrGHyPTF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43460d23-44c9-4b6d-cda2-8c71f22d2887"
      },
      "source": [
        "sample_indices"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[ 8],\n",
              "       [72],\n",
              "       [ 6],\n",
              "       [33],\n",
              "       [74],\n",
              "       [55],\n",
              "       [64],\n",
              "       [20],\n",
              "       [14],\n",
              "       [42],\n",
              "       [27],\n",
              "       [66],\n",
              "       [39],\n",
              "       [40],\n",
              "       [35],\n",
              "       [53],\n",
              "       [59],\n",
              "       [71],\n",
              "       [41],\n",
              "       [75],\n",
              "       [32],\n",
              "       [31],\n",
              "       [26],\n",
              "       [66],\n",
              "       [73],\n",
              "       [17],\n",
              "       [71],\n",
              "       [ 7],\n",
              "       [72],\n",
              "       [11],\n",
              "       [76],\n",
              "       [56],\n",
              "       [33],\n",
              "       [18],\n",
              "       [48],\n",
              "       [37],\n",
              "       [ 0],\n",
              "       [32],\n",
              "       [ 5],\n",
              "       [51],\n",
              "       [23],\n",
              "       [ 4],\n",
              "       [30],\n",
              "       [20],\n",
              "       [23],\n",
              "       [11],\n",
              "       [ 6],\n",
              "       [23],\n",
              "       [39],\n",
              "       [53],\n",
              "       [49],\n",
              "       [26],\n",
              "       [54],\n",
              "       [50],\n",
              "       [14],\n",
              "       [83],\n",
              "       [39],\n",
              "       [53],\n",
              "       [41],\n",
              "       [60],\n",
              "       [29],\n",
              "       [ 7],\n",
              "       [13],\n",
              "       [82],\n",
              "       [27],\n",
              "       [71],\n",
              "       [81],\n",
              "       [80],\n",
              "       [44],\n",
              "       [45],\n",
              "       [32],\n",
              "       [74],\n",
              "       [59],\n",
              "       [52],\n",
              "       [44],\n",
              "       [32],\n",
              "       [49],\n",
              "       [45],\n",
              "       [49],\n",
              "       [56],\n",
              "       [76],\n",
              "       [77],\n",
              "       [ 5],\n",
              "       [46],\n",
              "       [59],\n",
              "       [80],\n",
              "       [ 9],\n",
              "       [32],\n",
              "       [30],\n",
              "       [54],\n",
              "       [27],\n",
              "       [80],\n",
              "       [59],\n",
              "       [71],\n",
              "       [64],\n",
              "       [66],\n",
              "       [74],\n",
              "       [43],\n",
              "       [70],\n",
              "       [37],\n",
              "       [16],\n",
              "       [44],\n",
              "       [42],\n",
              "       [11],\n",
              "       [75],\n",
              "       [52],\n",
              "       [ 2],\n",
              "       [23],\n",
              "       [21],\n",
              "       [29],\n",
              "       [52],\n",
              "       [ 4],\n",
              "       [58],\n",
              "       [27],\n",
              "       [ 1],\n",
              "       [50],\n",
              "       [13],\n",
              "       [60],\n",
              "       [ 2],\n",
              "       [17]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyVoPy4HTBcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ffda321-9c0c-423c-93e6-4d16af9b7215"
      },
      "source": [
        "ind_to_char[sample_indices]# hence we perform tf.squeeze to reduce the sample indices by one dimension "
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[','],\n",
              "       ['q'],\n",
              "       ['('],\n",
              "       ['H'],\n",
              "       ['s'],\n",
              "       ['`'],\n",
              "       ['i'],\n",
              "       ['9'],\n",
              "       ['3'],\n",
              "       ['Q'],\n",
              "       ['B'],\n",
              "       ['k'],\n",
              "       ['N'],\n",
              "       ['O'],\n",
              "       ['J'],\n",
              "       [']'],\n",
              "       ['d'],\n",
              "       ['p'],\n",
              "       ['P'],\n",
              "       ['t'],\n",
              "       ['G'],\n",
              "       ['F'],\n",
              "       ['A'],\n",
              "       ['k'],\n",
              "       ['r'],\n",
              "       ['6'],\n",
              "       ['p'],\n",
              "       [')'],\n",
              "       ['q'],\n",
              "       ['0'],\n",
              "       ['u'],\n",
              "       ['a'],\n",
              "       ['H'],\n",
              "       ['7'],\n",
              "       ['W'],\n",
              "       ['L'],\n",
              "       ['\\n'],\n",
              "       ['G'],\n",
              "       [\"'\"],\n",
              "       ['Z'],\n",
              "       ['<'],\n",
              "       ['&'],\n",
              "       ['E'],\n",
              "       ['9'],\n",
              "       ['<'],\n",
              "       ['0'],\n",
              "       ['('],\n",
              "       ['<'],\n",
              "       ['N'],\n",
              "       [']'],\n",
              "       ['X'],\n",
              "       ['A'],\n",
              "       ['_'],\n",
              "       ['Y'],\n",
              "       ['3'],\n",
              "       ['}'],\n",
              "       ['N'],\n",
              "       [']'],\n",
              "       ['P'],\n",
              "       ['e'],\n",
              "       ['D'],\n",
              "       [')'],\n",
              "       ['2'],\n",
              "       ['|'],\n",
              "       ['B'],\n",
              "       ['p'],\n",
              "       ['z'],\n",
              "       ['y'],\n",
              "       ['S'],\n",
              "       ['T'],\n",
              "       ['G'],\n",
              "       ['s'],\n",
              "       ['d'],\n",
              "       ['['],\n",
              "       ['S'],\n",
              "       ['G'],\n",
              "       ['X'],\n",
              "       ['T'],\n",
              "       ['X'],\n",
              "       ['a'],\n",
              "       ['u'],\n",
              "       ['v'],\n",
              "       [\"'\"],\n",
              "       ['U'],\n",
              "       ['d'],\n",
              "       ['y'],\n",
              "       ['-'],\n",
              "       ['G'],\n",
              "       ['E'],\n",
              "       ['_'],\n",
              "       ['B'],\n",
              "       ['y'],\n",
              "       ['d'],\n",
              "       ['p'],\n",
              "       ['i'],\n",
              "       ['k'],\n",
              "       ['s'],\n",
              "       ['R'],\n",
              "       ['o'],\n",
              "       ['L'],\n",
              "       ['5'],\n",
              "       ['S'],\n",
              "       ['Q'],\n",
              "       ['0'],\n",
              "       ['t'],\n",
              "       ['['],\n",
              "       ['!'],\n",
              "       ['<'],\n",
              "       [':'],\n",
              "       ['D'],\n",
              "       ['['],\n",
              "       ['&'],\n",
              "       ['c'],\n",
              "       ['B'],\n",
              "       [' '],\n",
              "       ['Y'],\n",
              "       ['2'],\n",
              "       ['e'],\n",
              "       ['!'],\n",
              "       ['6']], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbLoOQubPTVe"
      },
      "source": [
        "sample_indices = tf.squeeze(sample_indices,axis = -1).numpy() #changes the dimension from (120,1) to (120,)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFuC52LjZUju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2197a5b4-5c58-4fba-8982-b6600d0bda66"
      },
      "source": [
        "sample_indices"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8, 72,  6, 33, 74, 55, 64, 20, 14, 42, 27, 66, 39, 40, 35, 53, 59,\n",
              "       71, 41, 75, 32, 31, 26, 66, 73, 17, 71,  7, 72, 11, 76, 56, 33, 18,\n",
              "       48, 37,  0, 32,  5, 51, 23,  4, 30, 20, 23, 11,  6, 23, 39, 53, 49,\n",
              "       26, 54, 50, 14, 83, 39, 53, 41, 60, 29,  7, 13, 82, 27, 71, 81, 80,\n",
              "       44, 45, 32, 74, 59, 52, 44, 32, 49, 45, 49, 56, 76, 77,  5, 46, 59,\n",
              "       80,  9, 32, 30, 54, 27, 80, 59, 71, 64, 66, 74, 43, 70, 37, 16, 44,\n",
              "       42, 11, 75, 52,  2, 23, 21, 29, 52,  4, 58, 27,  1, 50, 13, 60,  2,\n",
              "       17])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1HTMzHLkvOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2030da9c-3c7b-49af-a6ab-65f167015120"
      },
      "source": [
        "sample_indices.shape"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwS_T0WrZUm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b87637-ad7f-4765-ab24-1bcbb8a8ad14"
      },
      "source": [
        "ind_to_char[sample_indices]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([',', 'q', '(', 'H', 's', '`', 'i', '9', '3', 'Q', 'B', 'k', 'N',\n",
              "       'O', 'J', ']', 'd', 'p', 'P', 't', 'G', 'F', 'A', 'k', 'r', '6',\n",
              "       'p', ')', 'q', '0', 'u', 'a', 'H', '7', 'W', 'L', '\\n', 'G', \"'\",\n",
              "       'Z', '<', '&', 'E', '9', '<', '0', '(', '<', 'N', ']', 'X', 'A',\n",
              "       '_', 'Y', '3', '}', 'N', ']', 'P', 'e', 'D', ')', '2', '|', 'B',\n",
              "       'p', 'z', 'y', 'S', 'T', 'G', 's', 'd', '[', 'S', 'G', 'X', 'T',\n",
              "       'X', 'a', 'u', 'v', \"'\", 'U', 'd', 'y', '-', 'G', 'E', '_', 'B',\n",
              "       'y', 'd', 'p', 'i', 'k', 's', 'R', 'o', 'L', '5', 'S', 'Q', '0',\n",
              "       't', '[', '!', '<', ':', 'D', '[', '&', 'c', 'B', ' ', 'Y', '2',\n",
              "       'e', '!', '6'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q4d3r1bZcQh"
      },
      "source": [
        "epochs = 30"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVxraUsPZcVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ddb146-0073-44c2-931d-9a3654b8573a"
      },
      "source": [
        "model.fit(dataset,epochs=epochs)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "351/351 [==============================] - 54s 147ms/step - loss: 3.1763\n",
            "Epoch 2/30\n",
            "351/351 [==============================] - 53s 149ms/step - loss: 1.8778\n",
            "Epoch 3/30\n",
            "351/351 [==============================] - 54s 152ms/step - loss: 1.5457\n",
            "Epoch 4/30\n",
            "351/351 [==============================] - 54s 150ms/step - loss: 1.3866\n",
            "Epoch 5/30\n",
            "351/351 [==============================] - 55s 154ms/step - loss: 1.3091\n",
            "Epoch 6/30\n",
            "351/351 [==============================] - 54s 152ms/step - loss: 1.2610\n",
            "Epoch 7/30\n",
            "351/351 [==============================] - 55s 155ms/step - loss: 1.2249\n",
            "Epoch 8/30\n",
            "351/351 [==============================] - 55s 155ms/step - loss: 1.1990\n",
            "Epoch 9/30\n",
            "351/351 [==============================] - 55s 153ms/step - loss: 1.1765\n",
            "Epoch 10/30\n",
            "351/351 [==============================] - 55s 154ms/step - loss: 1.1584\n",
            "Epoch 11/30\n",
            "351/351 [==============================] - 54s 151ms/step - loss: 1.1424\n",
            "Epoch 12/30\n",
            "351/351 [==============================] - 55s 154ms/step - loss: 1.1250\n",
            "Epoch 13/30\n",
            "351/351 [==============================] - 54s 152ms/step - loss: 1.1130\n",
            "Epoch 14/30\n",
            "351/351 [==============================] - 56s 156ms/step - loss: 1.0991\n",
            "Epoch 15/30\n",
            "351/351 [==============================] - 56s 155ms/step - loss: 1.0875\n",
            "Epoch 16/30\n",
            "351/351 [==============================] - 55s 153ms/step - loss: 1.0750\n",
            "Epoch 17/30\n",
            "351/351 [==============================] - 55s 154ms/step - loss: 1.0628\n",
            "Epoch 18/30\n",
            "351/351 [==============================] - 54s 152ms/step - loss: 1.0516\n",
            "Epoch 19/30\n",
            "351/351 [==============================] - 56s 156ms/step - loss: 1.0412\n",
            "Epoch 20/30\n",
            "351/351 [==============================] - 55s 153ms/step - loss: 1.0313\n",
            "Epoch 21/30\n",
            "351/351 [==============================] - 55s 155ms/step - loss: 1.0234\n",
            "Epoch 22/30\n",
            "351/351 [==============================] - 55s 155ms/step - loss: 1.0154\n",
            "Epoch 23/30\n",
            "351/351 [==============================] - 55s 153ms/step - loss: 1.0070\n",
            "Epoch 24/30\n",
            "351/351 [==============================] - 55s 154ms/step - loss: 1.0016\n",
            "Epoch 25/30\n",
            "351/351 [==============================] - 54s 152ms/step - loss: 0.9939\n",
            "Epoch 26/30\n",
            "351/351 [==============================] - 56s 155ms/step - loss: 0.9872\n",
            "Epoch 27/30\n",
            "351/351 [==============================] - 55s 152ms/step - loss: 0.9832\n",
            "Epoch 28/30\n",
            "351/351 [==============================] - 55s 154ms/step - loss: 0.9786\n",
            "Epoch 29/30\n",
            "351/351 [==============================] - 55s 154ms/step - loss: 0.9753\n",
            "Epoch 30/30\n",
            "351/351 [==============================] - 55s 154ms/step - loss: 0.9720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8d394f1990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwD2veNaJ9Xp"
      },
      "source": [
        "model.save('shakespeare.h5')"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMKZYkJpPXHL"
      },
      "source": [
        "\r\n",
        "\r\n",
        "model = create_model(vocab_size,embed_dim,rnn_neurons,batch_size = 1)\r\n",
        "\r\n",
        "model.load_weights('shakespeare.h5')\r\n",
        "\r\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtW638bWvacX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cfdf499-a71a-41d1-fa84-908ec28c6fdf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (1, None, 64)             5376      \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (1, None, 1026)           3361176   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (1, None, 84)             86268     \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkxSIS7fvdst"
      },
      "source": [
        "def generate_text(model,start_seed,gen_size = 500, temp =1.0):\r\n",
        "\r\n",
        "  num_generate  = gen_size\r\n",
        "\r\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\r\n",
        "\r\n",
        "  input_eval = tf.expand_dims(input_eval,0)\r\n",
        "\r\n",
        "  text_generated = []\r\n",
        "\r\n",
        "  temperature = temp\r\n",
        "\r\n",
        "  model.reset_states()\r\n",
        "\r\n",
        "  for i in range(num_generate):\r\n",
        "\r\n",
        "    predictions = model(input_eval)\r\n",
        "\r\n",
        "    predictions = tf.squeeze(predictions,0)\r\n",
        "\r\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\r\n",
        "\r\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\r\n",
        "\r\n",
        "    text_generated.append(ind_to_char[predicted_id])\r\n",
        "\r\n",
        "  return (start_seed + ''.join(text_generated))"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2fgYfwovdv-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "5bf36f2f-a897-4b9f-9429-196af2a6d8ba"
      },
      "source": [
        "generate_text(model,\"Julius\",gen_size = 500,temp = 1.0)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Julius,\\n    For they are not half-joy of late.\\n    Go, my young lady ride, went to thee\\n    Who on my sorrow may receive it,\\n    If their better issue shrouds set down\\n    And take us het his beards! Please you too\\n    young men'ned. There's a good soldier, to ride thee now in Grother,\\n  And ask no tree, which, stoppedorking in,\\n    And, so did, by this, good women. Lucherous love,\\n    Taken I quoted.\\n  HORTENSIO. Not thee about thy hand! ANTUR't send her two bones\\n     told of beauty, lads like men, \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuwT49ILvdxi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}